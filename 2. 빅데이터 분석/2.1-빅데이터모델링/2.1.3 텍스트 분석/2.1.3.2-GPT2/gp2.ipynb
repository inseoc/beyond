{"nbformat":4,"nbformat_minor":0,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5-final"},"orig_nbformat":2,"kernelspec":{"name":"python385jvsc74a57bd06d46af94c2bbce495f1e668725902fa517c90b1782bcfe2fce0dd9868df553d3","display_name":"Python 3.8.5 64-bit (conda)"},"colab":{"name":"gp2.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"OGoHsRBfC8OW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619757136473,"user_tz":-540,"elapsed":4106,"user":{"displayName":"Sun-Ho KIM","photoUrl":"","userId":"02175564280531097476"}},"outputId":"b334aee8-0d62-4321-8191-9f4a52d81089"},"source":["pip install gluonnlp"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: gluonnlp in /usr/local/lib/python3.7/dist-packages (0.10.0)\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (0.29.22)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (20.9)\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (1.19.5)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp) (2.4.7)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KJEpBgYkPaCy","executionInfo":{"status":"ok","timestamp":1619754123195,"user_tz":-540,"elapsed":19782,"user":{"displayName":"Sun-Ho KIM","photoUrl":"","userId":"02175564280531097476"}},"outputId":"d0f68b66-4c15-4a89-fa38-a82d40d96683"},"source":["pip install mxnet"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting mxnet\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/07/66174e78c12a3048db9039aaa09553e35035ef3a008ba3e0ed8d2aa3c47b/mxnet-1.8.0.post0-py2.py3-none-manylinux2014_x86_64.whl (46.9MB)\n","\u001b[K     |████████████████████████████████| 46.9MB 62kB/s \n","\u001b[?25hRequirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (1.19.5)\n","Collecting graphviz<0.9.0,>=0.8.1\n","  Downloading https://files.pythonhosted.org/packages/53/39/4ab213673844e0c004bed8a0781a0721a3f6bb23eb8854ee75c236428892/graphviz-0.8.4-py2.py3-none-any.whl\n","Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (2.23.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n","Installing collected packages: graphviz, mxnet\n","  Found existing installation: graphviz 0.10.1\n","    Uninstalling graphviz-0.10.1:\n","      Successfully uninstalled graphviz-0.10.1\n","Successfully installed graphviz-0.8.4 mxnet-1.8.0.post0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hENUsd3vPaNF","executionInfo":{"status":"ok","timestamp":1619754129862,"user_tz":-540,"elapsed":26213,"user":{"displayName":"Sun-Ho KIM","photoUrl":"","userId":"02175564280531097476"}},"outputId":"c90d2344-a2ad-4423-ce87-3b2488ac0176"},"source":["pip install transformers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n","\u001b[K     |████████████████████████████████| 2.1MB 10.9MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 41.5MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Collecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 43.4MB/s \n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Installing collected packages: sacremoses, tokenizers, transformers\n","Successfully installed sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.5.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ocnYQVqVSm16","executionInfo":{"status":"ok","timestamp":1619754135900,"user_tz":-540,"elapsed":31957,"user":{"displayName":"Sun-Ho KIM","photoUrl":"","userId":"02175564280531097476"}},"outputId":"c4ddd304-dd0e-459b-bc1e-5ad8b5e7487d"},"source":["!pip install konlpy"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting konlpy\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n","\u001b[K     |████████████████████████████████| 19.4MB 1.7MB/s \n","\u001b[?25hCollecting colorama\n","  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n","Collecting beautifulsoup4==4.6.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n","\u001b[K     |████████████████████████████████| 92kB 10.6MB/s \n","\u001b[?25hRequirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n","Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n","Collecting JPype1>=0.7.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/a5/9781e2ef4ca92d09912c4794642c1653aea7607f473e156cf4d423a881a1/JPype1-1.2.1-cp37-cp37m-manylinux2010_x86_64.whl (457kB)\n","\u001b[K     |████████████████████████████████| 460kB 35.8MB/s \n","\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n","Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n","Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n","Installing collected packages: colorama, beautifulsoup4, JPype1, konlpy\n","  Found existing installation: beautifulsoup4 4.6.3\n","    Uninstalling beautifulsoup4-4.6.3:\n","      Successfully uninstalled beautifulsoup4-4.6.3\n","Successfully installed JPype1-1.2.1 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kA4Qb9IxTkrg","executionInfo":{"status":"ok","timestamp":1619754140532,"user_tz":-540,"elapsed":36336,"user":{"displayName":"Sun-Ho KIM","photoUrl":"","userId":"02175564280531097476"}},"outputId":"b4c39522-30b5-4f2d-bc28-4488e05cb7dc"},"source":["pip install wget"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting wget\n","  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n","Building wheels for collected packages: wget\n","  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wget: filename=wget-3.2-cp37-none-any.whl size=9681 sha256=f5568627c026387da04f28d23816c9bc92872abb288b4f76c5a79f566cb2d67c\n","  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n","Successfully built wget\n","Installing collected packages: wget\n","Successfully installed wget-3.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JgZaHfWGbUjB","executionInfo":{"status":"ok","timestamp":1619754144388,"user_tz":-540,"elapsed":39675,"user":{"displayName":"Sun-Ho KIM","photoUrl":"","userId":"02175564280531097476"}},"outputId":"958275cf-c769-4024-d352-6ac2d62ad580"},"source":["pip install sentencepiece"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n","\r\u001b[K     |▎                               | 10kB 18.0MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 21.0MB/s eta 0:00:01\r\u001b[K     |▉                               | 30kB 16.6MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 15.1MB/s eta 0:00:01\r\u001b[K     |█▍                              | 51kB 11.9MB/s eta 0:00:01\r\u001b[K     |█▋                              | 61kB 13.4MB/s eta 0:00:01\r\u001b[K     |██                              | 71kB 9.8MB/s eta 0:00:01\r\u001b[K     |██▏                             | 81kB 10.0MB/s eta 0:00:01\r\u001b[K     |██▌                             | 92kB 9.9MB/s eta 0:00:01\r\u001b[K     |██▊                             | 102kB 10.3MB/s eta 0:00:01\r\u001b[K     |███                             | 112kB 10.3MB/s eta 0:00:01\r\u001b[K     |███▎                            | 122kB 10.3MB/s eta 0:00:01\r\u001b[K     |███▌                            | 133kB 10.3MB/s eta 0:00:01\r\u001b[K     |███▉                            | 143kB 10.3MB/s eta 0:00:01\r\u001b[K     |████                            | 153kB 10.3MB/s eta 0:00:01\r\u001b[K     |████▍                           | 163kB 10.3MB/s eta 0:00:01\r\u001b[K     |████▋                           | 174kB 10.3MB/s eta 0:00:01\r\u001b[K     |█████                           | 184kB 10.3MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 194kB 10.3MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 204kB 10.3MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 215kB 10.3MB/s eta 0:00:01\r\u001b[K     |██████                          | 225kB 10.3MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 235kB 10.3MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 245kB 10.3MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 256kB 10.3MB/s eta 0:00:01\r\u001b[K     |███████                         | 266kB 10.3MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 276kB 10.3MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 286kB 10.3MB/s eta 0:00:01\r\u001b[K     |████████                        | 296kB 10.3MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 307kB 10.3MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 317kB 10.3MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 327kB 10.3MB/s eta 0:00:01\r\u001b[K     |█████████                       | 337kB 10.3MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 348kB 10.3MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 358kB 10.3MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 368kB 10.3MB/s eta 0:00:01\r\u001b[K     |██████████                      | 378kB 10.3MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 389kB 10.3MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 399kB 10.3MB/s eta 0:00:01\r\u001b[K     |███████████                     | 409kB 10.3MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 419kB 10.3MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 430kB 10.3MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 440kB 10.3MB/s eta 0:00:01\r\u001b[K     |████████████                    | 450kB 10.3MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 460kB 10.3MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 471kB 10.3MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 481kB 10.3MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 491kB 10.3MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 501kB 10.3MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 512kB 10.3MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 522kB 10.3MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 532kB 10.3MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 542kB 10.3MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 552kB 10.3MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 563kB 10.3MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 573kB 10.3MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 583kB 10.3MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 593kB 10.3MB/s eta 0:00:01\r\u001b[K     |████████████████                | 604kB 10.3MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 614kB 10.3MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 624kB 10.3MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 634kB 10.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 645kB 10.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 655kB 10.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 665kB 10.3MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 675kB 10.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 686kB 10.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 696kB 10.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 706kB 10.3MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 716kB 10.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 727kB 10.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 737kB 10.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 747kB 10.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 757kB 10.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 768kB 10.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 778kB 10.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 788kB 10.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 798kB 10.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 808kB 10.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 819kB 10.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 829kB 10.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 839kB 10.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 849kB 10.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 860kB 10.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 870kB 10.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 880kB 10.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 890kB 10.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 901kB 10.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 911kB 10.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 921kB 10.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 931kB 10.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 942kB 10.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 952kB 10.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 962kB 10.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 972kB 10.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 983kB 10.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 993kB 10.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.0MB 10.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.0MB 10.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.0MB 10.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.0MB 10.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.0MB 10.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1MB 10.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.1MB 10.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.1MB 10.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.1MB 10.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.1MB 10.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.1MB 10.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.1MB 10.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1MB 10.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.1MB 10.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.1MB 10.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2MB 10.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2MB 10.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2MB 10.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.2MB 10.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.2MB 10.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.2MB 10.3MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.95\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xfT3J9g1RzqZ","executionInfo":{"status":"ok","timestamp":1619766849404,"user_tz":-540,"elapsed":15075,"user":{"displayName":"Sun-Ho KIM","photoUrl":"","userId":"02175564280531097476"}}},"source":["import numpy as np\n","import pandas as pd\n","import os\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from transformers import BertTokenizer\n","import tensorflow as tf\n","from tensorflow import keras\n","import json\n","import re\n","from tqdm import tqdm\n","from konlpy.tag import Okt\n","import gluonnlp as nlp\n","from gluonnlp.data import SentencepieceTokenizer\n","from transformers import TFGPT2LMHeadModel"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VFwOGCwBmpG4"},"source":["# **GTP2를 활용한 한국어 언어 생성 모델**"]},{"cell_type":"code","metadata":{"id":"ytAMlImCPaZK","executionInfo":{"status":"ok","timestamp":1619766849408,"user_tz":-540,"elapsed":9703,"user":{"displayName":"Sun-Ho KIM","photoUrl":"","userId":"02175564280531097476"}}},"source":["class GPT2Model(tf.keras.Model):\n","  def __init__(self, dir_path):\n","    super(GPT2Model, self).__init__()\n","    self.gpt2 = TFGPT2LMHeadModel.from_pretrained(dir_path)\n","\n","  def call(self, inputs):\n","    return self.gpt2(inputs)[0]"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"nHBBiiCAS8mV"},"source":["import wget\n","import zipfile\n","\n","wget.download('https://github.com/NLP-kr/tensorflow-ml-nlp-tf2/releases/download/v1.0/gpt_ckpt.zip')\n","with zipfile.ZipFile('gpt_ckpt.zip') as z:\n","  z.extractall()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yGeUyg0LTz_4","executionInfo":{"status":"ok","timestamp":1619766881928,"user_tz":-540,"elapsed":23041,"user":{"displayName":"Sun-Ho KIM","photoUrl":"","userId":"02175564280531097476"}},"outputId":"3f4e9cb4-507b-4d8a-c53c-748b1f5065f3"},"source":["BASE_MODEL_PATH = '/content/gpt_ckpt'\n","gpt_model = GPT2Model(BASE_MODEL_PATH)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n","\n","All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at /content/gpt_ckpt.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"EXglymHfTz1s","executionInfo":{"status":"ok","timestamp":1619766884291,"user_tz":-540,"elapsed":747,"user":{"displayName":"Sun-Ho KIM","photoUrl":"","userId":"02175564280531097476"}}},"source":["TOKENIZER_PATH = '/content/gpt_ckpt/gpt2_kor_tokenizer.spiece'\n","tokenizer = SentencepieceTokenizer(TOKENIZER_PATH)\n","vocab = nlp.vocab.BERTVocab.from_sentencepiece(TOKENIZER_PATH,\n","                                               mask_token=None,\n","                                               sep_token=None,\n","                                               cls_token=None,\n","                                               unknown_token='<unk>',\n","                                               padding_token='<pad>',\n","                                               bos_token='<s>',\n","                                               eos_token='</s>')"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"mskTkP9kTznw","executionInfo":{"status":"ok","timestamp":1619766887719,"user_tz":-540,"elapsed":963,"user":{"displayName":"Sun-Ho KIM","photoUrl":"","userId":"02175564280531097476"}}},"source":["def generate_sent(seed_word, model, max_step=200, greedy=False, top_k=0, top_p=0.4):\n","  # 인자로 들어온 문장 생성을 시작할 단어를 문장을 의미하는 변수에 할당하고 토크아니즈한다.\n","  sent = seed_word\n","  toked = tokenizer(sent)\n","\n","  # 문장 생성을 하는 반복문\n","  # 토크나이즈된 단어를 인덱스로 반환하고 모델에 입력값으로 넣어 출력값을 받는다.\n","  # 모델의 출력값에 대해서는 문장에서 마지막 단어만 선택하게 한다.\n","  for _ in range(max_step):\n","    input_ids = tf.constant([vocab[vocab.bos_token],] + vocab[toked])[None, :] \n","    outputs = model(input_ids)[:, -1, :]\n","\n","\n","    if greedy:\n","      gen = vocab.to_tokens(tf.argmax(outputs, axis=-1).numpy().tolist()[0])\n","    else:\n","      output_logit = tf_top_k_top_p_filtering(outputs[0], top_k=top_k, top_p=top_p)\n","      gen = vocab.to_tokens(tf.random.categorical(output_logit, 1).numpy().tolist()[0])[0]\n","    if gen == '</s>':\n","      break\n","    sent += gen.replace(' ', ' ')\n","    toked = tokenizer(sent)\n","\n","  return sent"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9NNob436PEt-"},"source":["# - greedy 파라미터\n","모델에서 출력을 마쳤다면 출력한 마지막 토큰에서 가장 확률이 높은 단어를 선택하거나 확률이 높은 단어 중에서 확률 분로에 따라 선택할 수 있게 해야 한다.\n","\n","**greedy값이 True인 경우** tf.argmax로 가장 확률이 높은 단어를 선택하고 텍스트를 반환한다.\n","\n","**greedy값이 False인 경우** tf_top_k_p_filtering함수를 통해 무작위로 선택할 단어를 필터링한다.\n","그리고 tf.random.categorical을 통해 무작위로 선택한 단어들의 확률 분포를 토대로 무작위 선택을 하고 텍스트로 변환한다.\n","[여기서는 top_k 값을 0으로 설정하고 top_p만 조절해서 문장을 생성하는 뉴클러스 샘플링을 활용한다.]"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DNXR2jRVlE-m","executionInfo":{"status":"ok","timestamp":1619762881353,"user_tz":-540,"elapsed":28360,"user":{"displayName":"Sun-Ho KIM","photoUrl":"","userId":"02175564280531097476"}},"outputId":"5bccd45a-cec3-4451-dbde-cc3a5b4f5eaa"},"source":["print(generate_sent('이때', gpt_model, greedy=True,top_k=0, top_p=9.5))"],"execution_count":99,"outputs":[{"output_type":"stream","text":["이때▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OdR3lwzzl6UI"},"source":["# **소설 텍스트**"]},{"cell_type":"markdown","metadata":{"id":"tUFmd2c2nCz3"},"source":["소설 텍스트 데이터 전처리"]},{"cell_type":"code","metadata":{"id":"5asWIsZzlEvr","executionInfo":{"status":"ok","timestamp":1619766897022,"user_tz":-540,"elapsed":1510,"user":{"displayName":"Sun-Ho KIM","photoUrl":"","userId":"02175564280531097476"}}},"source":["import nltk\n","\n","DATA_IN_PATH = '/content/'\n","TRAIN_DATA_FILE = '셔츠남방.txt'\n","\n","sents = [s[:-1] for s in open(DATA_IN_PATH + TRAIN_DATA_FILE, 'r', encoding='utf-8').readlines()] #, encoding='utf-8'"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"yCI0d5R5UGPV","executionInfo":{"status":"ok","timestamp":1619766897024,"user_tz":-540,"elapsed":823,"user":{"displayName":"Sun-Ho KIM","photoUrl":"","userId":"02175564280531097476"}}},"source":["csv_test = pd.read_csv('/content/01_원피스_meta_data.csv')\n","csv_test2 = pd.read_csv('/content/02_스커트_치마_meta_data.csv')\n","csv_test3 = pd.read_csv('/content/03_자켓_meta_data.csv')\n","csv_test4 = pd.read_csv('/content/04_니트_스웨터_meta_data.csv')\n","csv_test5 = pd.read_csv('/content/08_반팔티셔츠_meta_data.csv')\n","\n","test = csv_test[['detail']]\n","test2 = csv_test2[['detail']]\n","test3 = csv_test3[['detail']]\n","test4 = csv_test4[['detail']]\n","test5 = csv_test5[['detail']]\n","\n","df = pd.concat([test, test2, test3, test4, test5])\n","a = df['detail'].tolist()\n","\n","sents = str(sents + a)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"jZ5vwcpklEan","executionInfo":{"status":"ok","timestamp":1619766910642,"user_tz":-540,"elapsed":12610,"user":{"displayName":"Sun-Ho KIM","photoUrl":"","userId":"02175564280531097476"}}},"source":["# 학습데이터는 텍스트를 먼저 문장별로 분리해둔 텍스트데이터이다.\n","\n","input_data = []\n","output_data = []\n","\n","# 언어 생성 모델은 다음 단어를 예측하는 데이터 구조로 구성\n","# 입력데이터를 tokens[:-1]로 맨 앞에서 맨 뒤 직전 토큰까지만 활용\n","# 정답데이터를 tokens[1:]로 맨 앞 다음 코든에서 맨 뒤 토큰까지 활용하게 한다.\n","\n","for s in sents:\n","  tokens = [vocab[vocab.bos_token],] + vocab[tokenizer(s)] + [vocab[vocab.eos_token],]\n","  input_data.append(tokens[:-1])\n","  output_data.append(tokens[1:])"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"MGGLaQuAqzBG","executionInfo":{"status":"ok","timestamp":1619766939307,"user_tz":-540,"elapsed":15095,"user":{"displayName":"Sun-Ho KIM","photoUrl":"","userId":"02175564280531097476"}}},"source":["from keras.preprocessing.sequence import pad_sequences\n","from keras.layers import Embedding\n","# pad_sequences함수를 활용하여 패딩\n","# np.array로 구성된 학습데이터 준비\n","\n","input_data = pad_sequences(input_data, 200, value=vocab[vocab.padding_token])\n","output_data = pad_sequences(output_data, 200, value=vocab[vocab.padding_token])\n","\n","input_data = np.array(input_data, dtype=np.int64)\n","output_data = np.array(output_data, dtype=np.int64)"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eAWcLFgRpQSS"},"source":["# **-** (구) 모델과 (신) 모델의 차이\n","과거 모델의 약점: 신조어나 줄임말에 대한 예측이 약함\n","예)RNN\n","\n","과거의 모델에 반해서 최신모델은 신조어나 줄임말에 대한 상대적인 강함을 보임. "]},{"cell_type":"markdown","metadata":{"id":"N-Qkh5k8pija"},"source":["# **- maxlen() **\n","maxlen은 metrlx를 형성하는 과정에서 모든 시퀀스 중 가장 긴 길이로 시퀀스 크기를 선정한다. 만약 문장의 길이가 가장 킨 시퀀스에 모자르면 나머지는 '0'으로 채워진다. \n","\n","무조건적으로 가장 긴 길이로 시퀀스로 정하는 것이 좋은 것이 아니며(->'0'이 많아지면 학습에 영향을 줌) 50%만 남기는 것은 아까운 일이다.(보통 75%정로로 선정) "]},{"cell_type":"markdown","metadata":{"id":"eJ1XQINSuZ6z"},"source":["# 소설 텍스트 미세 조정 모델"]},{"cell_type":"code","metadata":{"id":"q_86xiRgqy18","executionInfo":{"status":"ok","timestamp":1619766944386,"user_tz":-540,"elapsed":709,"user":{"displayName":"Sun-Ho KIM","photoUrl":"","userId":"02175564280531097476"}}},"source":["# loss와 accuracy\n","\n","loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n","    from_logits=True, reduction='none')\n","\n","train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')\n","\n","def loss_function(real, pred):\n","  mask = tf.math.logical_not(tf.math.equal(real, vocab[vocab.padding_token]))\n","  loss_ = loss_object(real, pred)\n","\n","  mask = tf.cast(mask, dtype=loss_.dtype)\n","  loss_ *= mask\n","\n","  return tf.reduce_mean(loss_)\n","\n","def accuracy_function(real, pred):\n","  mask = tf.math.logical_not(tf.math.equal(real, vocab[vocab.padding_token]))\n","  mask = tf.expand_dims(tf.cast(mask, dtype=pred.dtype), axis=-1)\n","  pred *= mask\n","\n","  acc = train_accuracy(real, pred)\n","\n","  return tf.reduce_mean(acc)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tc6YwiLKqysq","executionInfo":{"status":"ok","timestamp":1619766948561,"user_tz":-540,"elapsed":876,"user":{"displayName":"Sun-Ho KIM","photoUrl":"","userId":"02175564280531097476"}}},"source":["# gpt_model.compile을 통해 loss나 optimizer, metrics를 설정\n","gpt_model.compile(loss=loss_function,\n","                  optimizer=tf.keras.optimizers.Adam(1e-4),\n","                  metrics=[accuracy_function])"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"STTLVSx_F5N4","outputId":"099e4261-9455-4a69-9570-709eef654981"},"source":["BATCH_SIZE = 36\n","NUM_EPOCHS = 10\n","VALID_SPLIT = 0.2\n","\n","history = gpt_model.fit(input_data,\n","                        output_data,\n","                        batch_size=BATCH_SIZE,\n","                        epochs=NUM_EPOCHS,\n","                        validation_split=VALID_SPLIT)  "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n"," 4998/28866 [====>.........................] - ETA: 7:33:57 - loss: 0.0228 - accuracy_function: 0.0090"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZR9GTw_LGk3o","executionInfo":{"status":"ok","timestamp":1619754659360,"user_tz":-540,"elapsed":3202,"user":{"displayName":"Sun-Ho KIM","photoUrl":"","userId":"02175564280531097476"}},"outputId":"52d7c710-9a4b-4223-b4da-c59da080b39c"},"source":["# config.json과 tf_model.h5파일을 폴더에 저장\n","\n","DATA_OUT_PATH = \"./data_out\"\n","model_name = 'tf2_gp2_finetuned_model'\n","\n","save_dir_path = os.path.join(DATA_OUT_PATH, model_name)\n","save_file_path = os.path.join(save_dir_path, 'weights.h5')\n","\n","if not os.path.exists(save_dir_path):\n","  os.makedirs(save_dir_path)\n","\n","gpt_model.gpt2.save_pretrained(save_file_path)\n","load_gpt_model = GPT2Model(save_file_path)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n","\n","All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at ./data_out/tf2_gp2_finetuned_model/weights.h5.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"8RxFDSQhN9jS","executionInfo":{"status":"ok","timestamp":1619764127713,"user_tz":-540,"elapsed":28393,"user":{"displayName":"Sun-Ho KIM","photoUrl":"","userId":"02175564280531097476"}},"outputId":"b094efc2-d07f-4dd2-bce7-8271de1da1ff"},"source":["generate_sent('가디건, 빨강', gpt_model, greedy=True, top_k=0, top_p=0.5)"],"execution_count":135,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'가디건, 빨강,▁파랑,▁파랑,▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁'"]},"metadata":{"tags":[]},"execution_count":135}]}]}